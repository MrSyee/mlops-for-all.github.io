<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Jaeyeon Kim on</title><link>https://mlops-for-all.github.io/contributors/jaeyeon-kim/</link><description>Recent content in Jaeyeon Kim on</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Mon, 13 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://mlops-for-all.github.io/contributors/jaeyeon-kim/index.xml" rel="self" type="application/rss+xml"/><item><title>Why Kuberntes?</title><link>https://mlops-for-all.github.io/docs/introduction/why_kubernetes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://mlops-for-all.github.io/docs/introduction/why_kubernetes/</guid><description>MLOps &amp;amp; Kubernetes # 그렇다면 MLOps를 이야기할 때, 쿠버네티스(Kubernetes)라는 단어가 항상 함께 들리는 이유가 무엇일까요?
성공적인 MLOps 시스템을 구축하기 위해서는 MLOps의 구성요소 에서 설명한 것처럼 다양한 구성 요소들이 필요하지만, 각각의 구성 요소들이 유기적으로 운영되기 위해서는 인프라 레벨에서 수많은 이슈들을 해결해야 합니다.
간단하게는 수많은 머신러닝 모델의 학습 요청을 순차적으로 실행 하는 것, 다른 작업 공간에서도 동일한 실행 환경을 보장해야 하는 것, 배포된 서비스에 장애가 생겼을 때 빠르게 대응해야 하는 것 등의 이슈 등을 생각해볼 수 있습니다.</description></item><item><title>1. Introduction</title><link>https://mlops-for-all.github.io/docs/setup/intro/</link><pubDate>Mon, 13 Dec 2021 00:00:00 +0000</pubDate><guid>https://mlops-for-all.github.io/docs/setup/intro/</guid><description>MLOps 시스템 구축해보기 # MLOps 를 공부하는 데 있어서 가장 큰 장벽은 MLOps 시스템을 구성해보고 사용해보기가 어렵다는 점입니다. AWS, GCP 등의 퍼블릭 클라우드 혹은 Weight &amp;amp; Bias, neptune.ai 등의 상용 툴을 사용해보기에는 과금에 대한 부담이 존재하고, 처음부터 모든 환경을 혼자서 구성하기에는 어디서부터 시작해야 할 지 막막하게 느껴질 수밖에 없습니다.
이런 이유들로 MLOps 를 선뜻 시작해보지 못하시는 분들을 위해, 모두의 MLOps에서는 우분투가 설치되는 데스크탑 하나만 준비되어 있다면 MLOps 시스템을 밑바닥부터 구축하고 사용해 볼 수 있는 방법을 다룰 예정입니다.</description></item><item><title>2. Setup Kubernetes</title><link>https://mlops-for-all.github.io/docs/setup/kubernetes/</link><pubDate>Mon, 13 Dec 2021 00:00:00 +0000</pubDate><guid>https://mlops-for-all.github.io/docs/setup/kubernetes/</guid><description>Setup Kubernetes Cluster # 쿠버네티스를 처음 배우시는 분들에게 첫 진입 장벽은 쿠버네티스 실습 환경을 구축하는 것입니다.
프로덕션 레벨의 쿠버네티스 클러스터를 구축할 수 있게 공식적으로 지원하는 도구는 kubeadm 이지만, 사용자들이 조금 더 쉽게 구축할 수 있도록 도와주는 kubespray, kops 등의 도구도 존재하며, 학습 목적을 위해서 컴팩트한 쿠버네티스 클러스터를 정말 쉽게 구축할 수 있도록 도와주는 k3s, minikube, microk8s, kind 등의 도구도 존재합니다.
각각의 도구는 장단점이 다르기에 사용자마다 선호하는 도구가 다른 점을 고려하여, 본 글에서는 kubeadm, k3s, minikube 의 3 가지 도구를 활용하여 쿠버네티스 클러스터를 구축하는 방법을 다룹니다.</description></item><item><title>3. Setup Prerequisite</title><link>https://mlops-for-all.github.io/docs/setup/setup-pre-requisite/</link><pubDate>Mon, 13 Dec 2021 00:00:00 +0000</pubDate><guid>https://mlops-for-all.github.io/docs/setup/setup-pre-requisite/</guid><description>이 페이지에서는 쿠버네티스를 설치하기에 앞서, 클러스터와 클라이언트에 설치 혹은 설정해두어야 하는 컴포넌트들에 대한 매뉴얼을 설명합니다.
Install apt packages # 추후 클라이언트와 클러스터의 원활한 통신을 위해서는 Port-Forwarding 을 수행해야 할 일이 있습니다. Port-forwarding 을 위해서는 클러스터에 다음 패키지를 설치해주어야 합니다.
sudo apt-get update sudo apt-get install -y socat Install Docker # 도커 설치에 필요한 APT 패키지들을 설치합니다.
sudo apt-get update &amp;amp;&amp;amp; sudo apt-get install ca-certificates curl gnupg lsb-release 도커의 공식 GPG key 를 추가합니다.</description></item><item><title>4.2. Setup Kubernetes - Minikube</title><link>https://mlops-for-all.github.io/docs/setup/kubernetes-with-minikube/</link><pubDate>Mon, 13 Dec 2021 00:00:00 +0000</pubDate><guid>https://mlops-for-all.github.io/docs/setup/kubernetes-with-minikube/</guid><description>1. Prerequisite # 쿠버네티스 클러스터를 구축하기에 앞서, 필요한 구성요소들을 클러스터에 설치합니다.
Setup Prerequisite을 참고하여 Kubernetes를 설치하기 전에 필요한 요소들을 클러스터에 설치해 주시기 바랍니다.
Minikube binary # Minikube 를 사용하기 위해, v1.24.0 버전의 Minikube 바이너리를 설치합니다.
wget https://github.com/kubernetes/minikube/releases/download/v1.24.0/minikube-linux-amd64 sudo install minikube-linux-amd64 /usr/local/bin/minikube 정상적으로 설치되었는지 확인합니다.
minikube version 다음과 같은 메시지가 보이면 정상적으로 설치된 것을 의미합니다.
mlops@ubuntu:~$ minikube version minikube version: v1.24.0 commit: 76b94fb3c4e8ac5062daf70d60cf03ddcc0a741b 2. 쿠버네티스 클러스터 셋업 # 이제 Minikube 를 활용해 쿠버네티스 클러스터를 클러스터에 구축합니다.</description></item><item><title>5. Setup Kubernetes Modules</title><link>https://mlops-for-all.github.io/docs/setup/setup-kubernetes-module/</link><pubDate>Mon, 13 Dec 2021 00:00:00 +0000</pubDate><guid>https://mlops-for-all.github.io/docs/setup/setup-kubernetes-module/</guid><description>Helm # Helm 은 쿠버네티스 패키지와 관련된 리소스를 한 번에 배포하고 관리할 수 있게 도와주는 패키지 매니징 도구 중 하나입니다.
현재 폴더에 Helm v3.7.1 버전을 다운받습니다. wget https://get.helm.sh/helm-v3.7.1-linux-amd64.tar.gz helm 을 사용할 수 있도록 압축을 풀고, 파일의 위치를 변경합니다. tar -zxvf helm-v3.5.4-linux-amd64.tar.gz sudo mv linux-amd64/helm /usr/local/bin/helm 정상적으로 설치되었는지 확인합니다. helm help 다음과 같은 메시지가 보이면 정상적으로 설치된 것을 의미합니다.
The Kubernetes package manager Common actions for Helm: - helm search: search for charts - helm pull: download a chart to your local directory to view - helm install: upload the chart to Kubernetes - helm list: list releases of charts Environment variables: | Name | Description | |--------------------------|---------------------------------------------------------------------| | $HELM_CACHE_HOME | set an alternative location for storing cached files.</description></item><item><title>6. (Optional) Setup GPU</title><link>https://mlops-for-all.github.io/docs/setup/setup-nvidia-gpu/</link><pubDate>Mon, 13 Dec 2021 00:00:00 +0000</pubDate><guid>https://mlops-for-all.github.io/docs/setup/setup-nvidia-gpu/</guid><description>쿠버네티스 및 Kubeflow 등에서 GPU 를 사용하기 위해서는 다음 작업이 필요합니다.
1. Install NVIDIA Driver # nvidia-smi 수행 시 다음과 같은 화면이 출력된다면 이 단계는 스킵해 주시기 바랍니다.
mlops@ubuntu:~$ nvidia-smi +-----------------------------------------------------------------------------+ | NVIDIA-SMI 470.86 Driver Version: 470.86 CUDA Version: 11.4 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 NVIDIA GeForce .</description></item></channel></rss>